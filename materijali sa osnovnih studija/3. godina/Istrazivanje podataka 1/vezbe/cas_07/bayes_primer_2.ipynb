{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "# zadataka je da se za dat trening skup napravi term matrica\r\n",
    "# napraviti model za klasifikaciju pomocu multinomijalnog naivnog bajesa i trening skupa\r\n",
    "# klasifikuje test instanca X = Chinese Chinese Chinese Tokyo Japan\r\n",
    "\r\n",
    "# imamo ugradjeno u sklearn nacin da pravimo term matricu\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "\r\n",
    "import pandas as pd\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "# ovako izgleda tabela trening skup iz zadatka, ovo je glup primer jer dokumenti \r\n",
    "# imaju po mali broj reci\r\n",
    "# klasas je da li se tekst odnosi na kinu ili ne\r\n",
    "\r\n",
    "#  id_teksta |  reci u dokumentu          | klasa\r\n",
    "#        1   |   Chinese Beijing Chinese  | yes\r\n",
    "#        2   |   Chinese Chinese Shanghai | yes\r\n",
    "#        3   |   Chinese Macao            | yes\r\n",
    "#        4   |   Tokyo Japan Chinese      | no\r\n",
    "\r\n",
    "\r\n",
    "# term matrica je matrica gde su kolone reci, vrste su id teksta, a elementi matrice su broj pojavljivanja\r\n",
    "# te reci u tom dokumentu, mi bismo je na papiru napravili ovako:\r\n",
    "\r\n",
    "#  id_teksta | Chinese | Beijing | Shanghai | Macao | Tokyo | Japan\r\n",
    "#        1   |  2      |   1     |   0      |  0    |  0    |  0\r\n",
    "#        2   |  2      |   0     |   1      |  0    |  0    |  0\r\n",
    "#        3   |  1      |   0     |   0      |  1    |  0    |  0\r\n",
    "#        4   |  1      |   0     |   0      |  0    |  1    |  1\r\n",
    "\r\n",
    "\r\n",
    "corpus = [ 'Chinese Beijing Chinese',\r\n",
    "           'Chinese Chinese Shanghai', \r\n",
    "           'Chinese Macao',\r\n",
    "           'Tokyo Japan Chinese'\r\n",
    "         ]\r\n",
    "\r\n",
    "classes = ['yes', 'yes', 'yes', 'no']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "# CountVectorizer je transformacija, sve isto kao sto smo videli do sada, imamo fit i transform\r\n",
    "# mozemo da podesavamo dosta parametara, vidi dokumentaciju. Nesto korisno sto je po defaultu True je da\r\n",
    "# se sve reci pretvore u lowercase, da nebi imali posebne kolone za npr Chinese i chinese\r\n",
    "\r\n",
    "# NOTE: prvo smo radili ovako sa CountVectorizer, tu bas dobijemo broj pojavljivanja svake reci u svakom tekstu\r\n",
    "# vectorizer = CountVectorizer()\r\n",
    "\r\n",
    "# nakon toga smo uradili ovo. Setimo se na pocetku kada smo pricali o term matricama, da nam je pozeljno da\r\n",
    "# na neki nacin dodelimo neku vaznost svakoj reci, tj da koristimo term_frequency * log(nesto...) tj tf*idf\r\n",
    "# ovde necemo u matrici dobiti bas broj reci, vec neki broj izmedju 0 i 1 koji kaze koliko je ta rec\r\n",
    "# vazna za konkretan dokument. Tu je ideja bila da rec koja se cesto pojavljuje u mnogo dokumenata je manje \r\n",
    "# vazna nego neka specificna rec koja se malo puta pojvaljuje u nekom dokumentu (?)\r\n",
    "vectorizer = TfidfVectorizer()\r\n",
    "\r\n",
    "# mogli smo ovo i da izvedeomo iz dva koraka ovako:\r\n",
    "# naravimo obicna CountVectorizer()\r\n",
    "# na njega primenimo TfidfTransformer()\r\n",
    "\r\n",
    "# fit i transform mozemo uraditi i ovako u jednom koraku\r\n",
    "X_train = vectorizer.fit_transform(corpus)\r\n",
    "# ovim pozivom se dobija nekakva sparse matrica, tj matrica za koju se zna da ce vecina elemenata biti 0\r\n",
    "# takve matrice se pametno cuvaju u memoriji tako sto se cuvaju samo indeksi na kojima element nije 0\r\n",
    "# zajedno sa njihovim vrednostima\r\n",
    "print(X_train)\r\n",
    "print(type(X_train))\r\n",
    "# mozemo od ovoga dobiti i obicnu matricu koja je laksa za citanje\r\n",
    "print(X_train.toarray())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  (0, 0)\t0.6918346120039814\n",
      "  (0, 1)\t0.7220560017292982\n",
      "  (1, 4)\t0.6918346120039814\n",
      "  (1, 1)\t0.7220560017292982\n",
      "  (2, 3)\t0.8865476297873808\n",
      "  (2, 1)\t0.46263733109032296\n",
      "  (3, 2)\t0.6633846138519129\n",
      "  (3, 5)\t0.6633846138519129\n",
      "  (3, 1)\t0.34618161159873423\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "[[0.69183461 0.722056   0.         0.         0.         0.        ]\n",
      " [0.         0.722056   0.         0.         0.69183461 0.        ]\n",
      " [0.         0.46263733 0.         0.88654763 0.         0.        ]\n",
      " [0.         0.34618161 0.66338461 0.         0.         0.66338461]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "# ovako mozemod a vidimo sve reci koje postoje\n",
    "print(vectorizer.get_feature_names())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['beijing', 'chinese', 'japan', 'macao', 'shanghai', 'tokyo']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "# jos jedan nacin da lepo vidimo term matricu je da od nje napravimo pd.Dataframe, onda imamo lep ispis gde\n",
    "# se vidi i id dokumenta i same reci i broj pojavljivanja\n",
    "pd.DataFrame(X_train.toarray(), columns=vectorizer.get_feature_names())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    beijing   chinese     japan     macao  shanghai     tokyo\n",
       "0  0.691835  0.722056  0.000000  0.000000  0.000000  0.000000\n",
       "1  0.000000  0.722056  0.000000  0.000000  0.691835  0.000000\n",
       "2  0.000000  0.462637  0.000000  0.886548  0.000000  0.000000\n",
       "3  0.000000  0.346182  0.663385  0.000000  0.000000  0.663385"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beijing</th>\n",
       "      <th>chinese</th>\n",
       "      <th>japan</th>\n",
       "      <th>macao</th>\n",
       "      <th>shanghai</th>\n",
       "      <th>tokyo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.691835</td>\n",
       "      <td>0.722056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.722056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.691835</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.462637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.886548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346182</td>\n",
       "      <td>0.663385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.663385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "# multinomijalni bajes je pogodan za podatke gde mi nesto brojimo, tj imamo frekvencije koliko se cesto \n",
    "# nesto javlja, u nasem slucaju frekvencije reci. To se lepo vidi i razume zasto radi za obican CountVecotirzer\n",
    "# ali radi kako treba i za ovaj tfidf iako mozda nije intuitivno\n",
    "model = MultinomialNB()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "model.fit(X_train, classes)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "test_doc = 'Chinese Chinese Chinese Tokyo Japan'\n",
    "# pre nego sto za nasu test instancu uradimo predict, moramo od nje napraviti oblik pogodan za model\n",
    "# tj moramo i od nje da naparvimo term matricu (moramo da ga prosledimo kao listu jer transform ocekuje listu)\n",
    "X_test = vectorizer.transform([test_doc])\n",
    "X_test.toarray()\n",
    "\n",
    "print(model.predict(X_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['yes']\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}